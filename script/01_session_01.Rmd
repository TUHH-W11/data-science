# (PART) Session 1 {-}
# Overview
#  `r fa("r-project", fill = "black")` Introduction to the tidyverse {#session_01_01}

```{r data-science-workflow_1, echo=FALSE, fig.cap='Project structure example in RStudio.', out.width='100%'}
knitr::include_graphics('input/session_01/01_images/data_science_workflow.png', dpi = NA)
```

```{r data-science-workflow_2, echo=FALSE, fig.cap='Typical Tidyverse Workflow', out.width='100%'}
knitr::include_graphics('input/session_01/01_images/tidyverse.png', dpi = NA)
```

The tidyverse is a collection of R packages developed by RStudio’s chief scientist Hadley Wickham. These packages work well together as part of larger data analysis pipeline. To learn more about these tools and how they work together, read R for data science.

The following tutorial will introduce some basic functions in tidyverse for structuring and analyzing datasets. This is the first in a three-part series on cleaning data to visualize it in R using the tidyverse.

## **IMPORT** - Loading data with readr / readxl
Before you can manipulate data with R, you need to import the data into R’s memory, or build a connection to the data that R can use to access the data remotely.

How you import your data will depend on the format of the data. The most common way to store small data sets is as a plain text file. Data may also be stored in a proprietary format associated with a specific piece of software, such as SAS, SPSS, or Microsoft Excel. Data used on the internet is often stored as a JSON or XML file. Large data sets may be stored in a database or a distributed storage system.

When you import data into R, R stores the data in your computer’s RAM while you manipulate it. This creates a size limitation: truly big data sets should be stored outside of R in a database or distributed storage system. You can then create a connection to the system that R can use to access the data without bringing the data into your computer’s RAM.

The tidyverse offers the following packages for importing data:

* `readr` for reading flat files like .csv files
* `readxl` for .xls and .xlsx sheets.
* `haven` for SPSS, Stata, and SAS data.
* `googledrive` to interact with files on Google Drive from R.

<style>
.column{
  float: left;
  width: 25%;
  padding: 5px;
}

.row::after{
  content: "";
  clear: both;
  display: table;
}
</style>


```{r r-import, echo=FALSE}
knitr::asis_output(htmltools::htmlPreserve('
<style>
.column{
  float: left;
  width: 25%;
  padding: 5px;
}

.row::after{
  content: "";
  clear: both;
  display: table;
}
</style>
<div class="row">
  <div class="column">
    <a href="https://readr.tidyverse.org" target="_blank">
      <img src="input/session_01/01_images/logo_readr.svg" alt="CAPTION" style="width:100%">
    </a>
  </div>
  <div class="column">
    <a href="https://readxl.tidyverse.org" target="_blank">
      <img src="input/session_01/01_images/logo_readxl.svg" alt="Snow" style="width:100%">
    </a>
  </div>
  <div class="column">
    <a href="https://haven.tidyverse.org" target="_blank">
      <img src="input/session_01/01_images/logo_haven.svg" alt="Forest" style="width:100%">
    </a>
  </div>
  <div class="column">
    <a href="https://googledrive.tidyverse.org" target="_blank">
      <img src="input/session_01/01_images/logo_googledrive.svg" alt="Mountains" style="width:100%">
    </a>
  </div>
</div>
<p class="caption">Click on the images to get more information</p>
'))
```

There are a handful of other packages that are not in the tidyverse, but are tidyverse-adjacent. They are very useful for importing data from other sources:

* [jsonlite](https://github.com/jeroen/jsonlite#jsonlite) for JSON.
* [xml2](https://github.com/r-lib/xml2) for XML.
* [httr](https://github.com/r-lib/httr) for web APIs.
* [rvest](https://github.com/hadley/rvest) for web scraping.
* [DBI](https://github.com/rstats-db/DBI) for relational databases. To connect to a specific database, you’ll need to pair DBI with a specific backend like RSQLite, RPostgres, or odbc. Learn more at [https://db.rstudio.com](https://db.rstudio.com).


<font size="5"><b>Example</b></font>
```{r, eval=F}
# Loading data (can also be achieved by clicking on "Import Dataset > From Text (readr)" in the upper right corner)
library(readr)
dataset_tbl <- read_csv("data.csv"))

# Writing data
write_csv(dataset_tbl, "data.csv")

# Saving in csv (or tsv) does mean you loose information about the type of data in particular columns. You can avoid this by using  write_rds() and read_rds() to read/write objects in R binary rds format.
write_rds(dataset_tbl, "data.rds")
```



## Pipes
<a href="https://magrittr.tidyverse.org">
<img src="input/session_01/01_images/logo_pipe.svg" align="right" style="width:250px; height:250px; padding:10px"/>
</a>
Pipes are a powerful tool for clearly expressing a sequence of multiple operations. You will be using the “pipe”-operator `%>%` throughout this class. The “pipe” is from the `magrittr` package. The point of the pipe is to help you write code in a way that is easier to read and understand. It makes your code more readable by structuring sequences of data operations left-to-right (as opposed to from the inside and out). The pipe makes your code read more like a sentence, branching from left to right. You can read it as a series of imperative statements: group, then summarise, then filter. As suggested by this reading, a good way to pronounce `%>%` when reading code is “then”. Mathematically it can be expressed like the following:

* `x %>% f` is equivalent to `f(x)`
* `x %>% f(y)` is equivalent to `f(x, y)`
* `x %>% f %>% g %>% h` is equivalent to `h(g(f(x)))`


Instead of writing this:

```
data <- iris
data <- head(data, n=3)
```

you can write the code like this:

``` r
# The easiest way to get magrittr is to load the whole tidyverse:
library("tidyverse")
# Alternatively, load just magrittr:
library("magrittr")

iris %>% head(n=3)
```
<font size="5"><b>Example</b></font>
When coupling several function calls with the pipe-operator, the benefit will become more apparent. Consider this pseudo example:

## Tibbles
<a href="https://tibble.tidyverse.org/">
<img src="input/session_01/01_images/logo_tibble.svg" align="right" style="width:250px; height:250px; padding:10px"/>
</a>
Throughout this class we work with “tibbles” instead of R’s traditional `data.frame`. Tibbles are data frames, but they tweak some older behaviours to make life a little easier. R is an old language, and some things that were useful 10 or 20 years ago now get in your way.
In most places, the term tibble and data frame will be used interchangeably.

* tibble is one of the unifying features of tidyverse,
* it is a better data.frame realization,
* objects data.frame can be coerced to tibble using as_tibble()

When you print a tibble:
* all columns that fit the screen are shown,
* first 10 rows are shown,
* data type for each column is shown.

```
 tibble(
    x = 1,          # recycling
    y = runif(50), 
    z = x + y^2,
    outcome = rnorm(50)
  )
```

```
as_tibble(cars)
```

Subsetting tibbles

```
vehicles <- as_tibble(cars[1:5,])
vehicles[['speed']]
vehicles[[1]]
vehicles$speed
# Using placeholders
vehicles %>% .$dist
vehicles %>% .[['dist']]
vehicles %>% .[[2]]
```



## **TIDY** - Reshaping your data with tidyr
<a href="https://tidyr.tidyverse.org/">
<img src="input/session_01/01_images/logo_tidyr.svg" align="right" style="width:250px; height:250px; padding:10px"/>
</a>
The Concept of Tidy Data

* each and every observation is represented as exactly one row,
* each and every variable is represented by exactly one column,
* thus each data table cell contains only one value.

```{r tidy-data, echo=FALSE, fig.cap='The concept of tidy data', out.width='100%'}
knitr::include_graphics('input/session_01/01_images/tidy_data.png', dpi = NA)
```

Usually data are untidy in only one way. However, if you are unlucky, they are really untidy and thus a pain to work with...

For the following example is the Diamonds Dataset used from the ggplot2 package.

`gather()`: Use, if some of your column names are actually values of a variable

```{r, eval = TRUE, echo=FALSE}
library(tidyverse)
diamonds2 <- readRDS("input/session_01/02_R/diamonds2.rds")
```

```{r, eval = TRUE}
diamonds2

diamonds2 %>% 
  gather(`2008`, `2009`, key = 'year', value = 'price')
```

`spread()`: Use, if some of your observations are scattered across many rows
```r
bijou3
```
```r
bijou3 %>% 
  spread(key=dimension, value=measurement) %>% 
  head(n = 5)
```

## **TRANSFORM** - Data Transformations with dplyr
<a href="https://dplyr.tidyverse.org/">
<img src="input/session_01/01_images/logo_dplyr.svg" align="right" style="width:250px; height:250px; padding:10px"/>
</a>
Often you’ll need to create some new variables or summaries, or maybe you just want to rename the variables or reorder the observations in order to make the data a little easier to work with. dplyr is a grammar of data manipulation, providing a consistent set of verbs that help you solve the most common data manipulation challenges. The following five key dplyr functions allow you to solve the vast majority of your data manipulation challenges:

* **`filter()`** picks cases based on their values. So it can be used for selecting the relevant rows.

```{r}
diamonds %>% 
    filter(cut == 'Ideal' | cut == 'Premium', carat >= 0.23) %>% 
    head(5)
```
---

* **`arrange()`** changes the ordering of the rows

```{r}
diamonds %>% 
  arrange(cut, carat, desc(price))
```

The NAs always end up at the end of the rearranged tibble.

---

* **`select()`** picks variables based on their names

```{r}
diamonds %>% 
  select(color, clarity, x:z) %>% 
  head(n = 5)
```

Exclusive select:

```{r}
diamonds %>% 
  select(-(x:z)) %>% 
  head(n = 5)
```


Select helpers

use everything() to bring some columns to the front:

bijou %>% select(x:z, everything()) %>% head(n = 5)

---

* **`rename()`**
```{r}
diamonds %>% 
  rename(var_x = x) %>% 
  head(n = 5)
```

---

* **`mutate()`** adds new variables that are functions of existing variables. **`transmute()`**
```{r}
diamonds %>% 
  mutate(p = x + z, q = p + y) %>% 
  select(-(depth:price)) %>% 
  head(n = 5)
```


```{r}
diamonds %>% 
  transmute(carat, cut, sum = x + y + z) %>% 
  head(n = 5)
```

---

* **`group_by()`** and **`summarize()`** reduces multiple values down to a single summary
```{r}
diamonds %>% 
  group_by(cut) %>% 
  summarize(max_price = max(price),
            mean_price = mean(price),
            min_price = min(price))
```

* **`glimpse()`**



## Lubridate
<a href="https://lubridate.tidyverse.org/">
<img src="input/session_01/01_images/logo_lubridate.svg" align="right" style="width:250px; height:250px; padding:10px"/>
</a>

## Stringr
<a href="https://stringr.tidyverse.org">
<img src="input/session_01/01_images/logo_stringr.svg" align="right" style="width:250px; height:250px; padding:10px"/>
</a>

## Purrr
needed here?


<!-- +++++++++++ -->
<!-- 1st Project -->
<!-- +++++++++++ -->
#  `r fa("user-tie", fill = "black")` Business case - Sales Analysis

<font size="4">Sales Analysis Overview</font>

**Overall goals**

Introductory words ... You are a data scientist. Your assignment is to ...

* study the products ...
* looking for opportunities to sell new producgts
* better serve the customer
* better market the products

* justify it by data ...

**Goals for this session** 

* Get your hands into R with a real world situation
* Analyze Sales over time of products sold through the Olist Store
    + Sales by Year
    + Sales by secondary product category
  
**Steps**

1. Import
    + flatfiles
    + databases
    + scrape
2. Wrangle data
    + examine data
    + clean data
    + join data
3. Visualize data

**Context**
Olist is the largest department store in Brazilian marketplaces. Olist connects small businesses from all over Brazil to channels without hassle and with a single contract. Those merchants are able to sell their products through the Olist Store and ship them directly to the customers using Olist logistics partners. See more on their website: [www.olist.com](www.olist.com)

After a customer purchases the product from Olist Store a seller gets notified to fulfill that order. Once the customer receives the product, or the estimated delivery date is due, the customer gets a satisfaction survey by email where he can give a note for the purchase experience and write down some comments.

```{r olist-example-page, echo=FALSE, fig.cap='Project structure example in RStudio.', out.width='100%'}
knitr::include_graphics('input/session_01/01_images/olist_example_page.png', dpi = NA)
```


## Theory / Background
### Transactional data

```{r transactional-data, echo=FALSE, fig.cap='Project structure example in RStudio.', out.width='100%'}
knitr::include_graphics('input/session_01/01_images/transactional_data.png', dpi = NA)
```
The Entity Relationship Diagram (ERD)
Types of database relationships (1-to-1, 1-to-many,many-to-many)



### data schema

The data is divided in multiple datasets for better understanding and organization. Please refer to the following data schema when working with it:

```{r olist-structure-01, echo=FALSE, fig.cap='Project structure example in RStudio.', out.width='100%'}
knitr::include_graphics('input/session_01/01_images/olist_structure_01.png', dpi = NA)
```

* insert explanation and screenshots of the excel files

The dataset has information of 100k orders from 2016 to 2018 made at multiple marketplaces in Brazil. Its features allows viewing an order from multiple dimensions: from order status, price, payment and freight performance to customer location, product attributes and finally reviews written by customers. In addition a geolocation dataset that relates Brazilian zip codes to lat/lng coordinates is released.

This is real commercial data, it has been anonymised, and references to the companies and partners in the review text have been replaced with the names of Game of Thrones great houses.

**Attention**

1. An order might have multiple items.
2. Each item might be fulfilled by a distinct seller.
3. All text identifying stores and partners where replaced by the names of Game of Thrones great houses.

It was also a Marketing Funnel Dataset released. Both datasets may be joined to see an order from Marketing perspective!

```{r olist-structure-02, echo=FALSE, fig.cap='Project structure example in RStudio.', out.width='100%'}
knitr::include_graphics('input/session_01/01_images/olist_structure_02.png', dpi = NA)
```

**Inspiration**

Here are some inspiration for possible outcomes from this dataset.

NLP: 

This dataset offers a supreme environment to parse out the reviews text through its multiple dimensions.

Clustering:

Some customers didn't write a review. But why are they happy or mad?

Sales Prediction:

With purchase date information you'll be able to predict future sales.

Delivery Performance:

You will also be able to work through delivery performance and find ways to optimize delivery times.

Product Quality: 

Enjoy yourself discovering the products categories that are more prone to customer insatisfaction.

Feature Engineering: 

Create features from this rich dataset or attach some external public information to it.


## Project Setup
### Project structure

```{block, type='rmdblankbox'}
Download
```
```{block, type='rmdattachment'}
**[DS_business_case.zip](https://github.com/TUHH-W11/data-science/blob/master/script/input/session_01/03_files/DS_business_case.zip)**
```

```{r project-structure, echo=FALSE, fig.cap='Project structure example in RStudio.', out.width='100%'}
knitr::include_graphics('input/session_01/01_images/project_structure.png', dpi = NA)
```

### Setup (Template File)

Download the template we will be using for the analysis

```{block, type='rmdblankbox'}
Download
```
```{block, type='rmdattachment'}
**[s01-02_sales_analysis.R](https://github.com/)**
```

The content of the file looks like this:

````{r, eval = F}
# datascience at NIT ------------------------------------------------------

# 1.0 Load libraries ----
library(tidyverse)
library(lubridate)
library(tidyquant)
library(readxl)
library(writexl)

# 2.0 Importing Files ----





# 3.0 Examining Data ----





# 4.0 Joining Data ----




# 5.0 Wrangling Data ----





# 6.0 Business Insights ----


# 6.1 Sales by Year ----

# Step 1 - Manipulate




# Step 2 - Visualize



# 6.2 Sales by Year and Category 2 ----


# Step 1 - Manipulate




# Step 2 - Visualize




# 7.0 Writing Files ----


# 7.1 Excel ----


# 7.2 CSV ----


# 7.3 RDS ----
```


### Installing Packages

```{block, type='rmdblankbox'}
Download
```
```{block, type='rmdattachment'}
**[session_01_install_pkgs.R](https://github.com/TUHH-W11/data-science/blob/master/script/input/session_01/02_R/session_01_install_pkgs.R)**
```

package deoendencies

c operatior stands for combining elements

control + enter or cmd + enter

global environment

output to the screen (print)

comments (not being added to the cvector)

explanation of the right hand corner (packages, etc)

Errors: what to do in case of errors during installation (maybe Rtools is needed, windows users)

Doy you want to install from source the packages which need compilation

###  `r fa("flag-checkered", fill = "black")` Checkpoint

* Key Checks at this Point
* User Library Verification
* Directory Structure Verification


## Import
###  `r fa("flag-checkered", fill = "black")` Checkpoint

## Examine

regular print (output tibble to console)
open data window (view() function), filtering etc.
glimpse() function (prints it out in a transpose fashoin)

--> Objective: Combine the three tibbles into one that can be analyzed


## Cleaning and joining data

```r
library(dplyr)
library(tidyr)
library(tidyverse)
```

left_join, rbind, filtering, naming, pipe operator, ...
group_by, summarize


###  `r fa("flag-checkered", fill = "black")` Checkpoint

## Session 01 Challenge

```{block, type='rmdblankbox'}
Download
```
```{block, type='rmdattachment'}
**[sales_analysis.rmd](https://github.com/)**
```

Rmarkdown file with instructions!
```
# ---
#   title: "Week 2 Challenge"
# author: "Business Science"
# date: "12/30/2018"
# output: 
#   html_document:
#   toc: TRUE
# theme: flatly
# highlight: tango
# code_folding: show
# ---
#   
#   ```{r setup, include=FALSE}
# knitr::opts_chunk$set(
#   echo = TRUE
# )
# ```
# 
# # Challenge Summary
# 
# This is a short challenge to begin applying what you are learning to the problem at hand. You will go through a series of questions related to the course project goals: 
#   
#   1. Coming up with a new product idea, and 
# 
# 2. Segmenting the customer-base
# 
# # Objectives
# 
# 1. Apply `dplyr` and `tidyr` functions to answer questions related to the course projects. 
# 
# 2. Gain exposure to `rmarkdown`
# 
# # Data
# 
# To read the data, make sure that the paths point to the appropriate data sets. Saving the file in the main directory should enable the paths to be detected correctly. 
# 
# ```{r, message=FALSE, warning=FALSE}
# # Load libraries
# library(tidyverse)
# ```
# 
# ```{r}
# # Read bike orderlines data
# path_bike_orderlines <- "00_data/bike_sales/data_wrangled/bike_orderlines.rds"
# bike_orderlines_tbl <- read_rds(path_bike_orderlines)
# 
# glimpse(bike_orderlines_tbl)
# ```
# 
# ```{r}
# # Read bikes data
# path_bikes <- "00_data/bike_sales//data_raw/bikes.xlsx"
# bikes_tbl <- readxl::read_excel(path_bikes)
# 
# glimpse(bikes_tbl)
# ```
# 
# # Questions
# 
# 
# 
# ## 1. What are the unique categories of products? (Difficulty = Low)
# 
# - Begin with `bike_orderlines_tbl`
# - Use `distinct()` to evaluate 
# 
# Review Primary Product Category (`category_1`).
# 
# ```{r}
# 
# ```
# 
# 
# Review Secondary Product Category (`category_2`).
# 
# ```{r}
# 
# ```
# 
# Review Frame Material (`frame_material`).
# 
# ```{r}
# 
# ```
# 
# 
# ## 2. Which product categories have the most sales? (Difficulty = Medium)
# 
# - Select appropriate columns from `bike_orderlines_tbl`
# - Group and summarize the data calling the new column `Sales`. Make sure to ungroup. 
# - Arrange descending by `Sales`
# - Rename column names to `Primary Category`, `Secondary Category`, or `Frame Material` (as appropriate).
# - Format the Sales as `dollar()` 
# 
# Review Primary Product Category (`category_1`).
# 
# ```{r}
# 
# 
# ```
# 
# Review Secondary Product Category (`category_2`).
# 
# ```{r}
# 
# 
# ```
# 
# 
# Review Frame Material (`frame_material`).
# 
# ```{r}
# 
# 
```

## Session 01 Solution

```{block, type='rmdblankbox'}
Download
```
```{block, type='rmdattachment'}
**[session_01_solution.R](https://github.com/)**
```

```{r rev-by-year, echo=FALSE, fig.cap='Project structure example in RStudio.', out.width='100%'}
knitr::include_graphics('input/session_01/01_images/Rplot.png', dpi = NA)
```


```r
# DS4B 101-R: R FOR BUSINESS ANALYSIS ----
# JUMPSTART: First Sales Analysis ----

# 1.0 Load libraries ----

# Work horse packages
library(tidyverse)
library(lubridate)

# theme_tq()
library(tidyquant)

# Excel Files
library(readxl)
library(writexl)




# 2.0 Importing Files ----

?read_excel()

bikes_tbl <- read_excel(path = "00_data/bike_sales/data_raw/bikes.xlsx")

bikeshops_tbl <- read_excel("00_data/bike_sales/data_raw/bikeshops.xlsx")

orderlines_tbl <- read_excel("00_data/bike_sales/data_raw/orderlines.xlsx")
names(orderlines_tbl)[1] <- "X__1"



# 3.0 Examining Data ----

bikes_tbl

glimpse(bikes_tbl)

bikeshops_tbl

orderlines_tbl

# 4.0 Joining Data ----

?left_join

orderlines_tbl

bikes_tbl

left_join(orderlines_tbl, bikes_tbl, by = c("product.id" = "bike.id"))

bike_orderlines_joined_tbl <- orderlines_tbl %>%
    left_join(bikes_tbl, by = c("product.id" = "bike.id")) %>%
    left_join(bikeshops_tbl, by = c("customer.id" = "bikeshop.id"))

bike_orderlines_joined_tbl

bike_orderlines_joined_tbl %>% glimpse()

# 5.0 Wrangling Data ----

bike_orderlines_wrangled_tbl <- bike_orderlines_joined_tbl %>%
    
    # Separate description into category.1, category.2, and frame.material
    separate(description,
             into = c("category.1", "category.2", "frame.material"),
             sep = " - ",
             remove = TRUE) %>%
    
    # Separate location into city and state
    separate(location,
             into = c("city", "state"),
             sep  = ", ",
             remove = FALSE) %>%
    
    # price extended
    mutate(total.price = price * quantity) %>%
    
    # Reorganize
    select(-X__1, -location) %>%
    select(-ends_with(".id")) %>%
    
    bind_cols(bike_orderlines_joined_tbl %>% select(order.id)) %>%
    
    # Reorder columns
    select(contains("date"), contains("id"), contains("order"),
           quantity, price, total.price,
           everything()) %>%
    
    # Renaming columns
    rename(order_date = order.date) %>%
    set_names(names(.) %>% str_replace_all("\\.", "_")) 

bike_orderlines_wrangled_tbl %>% glimpse()



# 6.0 Business Insights ----


# 6.1 Sales by Year ----

# Step 1 - Manipulate

sales_by_year_tbl <- bike_orderlines_wrangled_tbl %>%
    
    # Selecting columns to focus on and adding a year column
    select(order_date, total_price) %>%
    mutate(year = year(order_date)) %>%
    
    # Grouping by year, and summarizing sales
    group_by(year) %>%
    summarize(sales = sum(total_price)) %>%
    ungroup() %>%
    
    # $ Format Text
    mutate(sales_text = scales::dollar(sales))
    
sales_by_year_tbl


# Step 2 - Visualize

sales_by_year_tbl %>%
    
    # Setup canvas with year (x-axis) and sales (y-axis)
    ggplot(aes(x = year, y = sales)) +
    
    # Geometries
    geom_col(fill = "#2c3e50") +
    geom_label(aes(label = sales_text)) +
    geom_smooth(method = "lm", se = FALSE) +
    
    # Formatting
    theme_tq() +
    scale_y_continuous(labels = scales::dollar) +
    labs(
        title = "Revenue by Year",
        subtitle = "Upward trend",
        x = "",
        y = "Revenue"
    )

# 6.2 Sales by Year and Category 2 ----


# Step 1 - Manipulate

sales_by_year_cat_2_tbl <- bike_orderlines_wrangled_tbl %>%
    
    # Selecting columns and add a year
    select(order_date, total_price, category_2) %>%
    mutate(year = year(order_date)) %>%
    
    # Groupby and Summarize year and category 2
    group_by(year, category_2) %>%
    summarise(sales = sum(total_price)) %>%
    ungroup() %>%
    
    # Format $ Text
    mutate(sales_text = scales::dollar(sales))


sales_by_year_cat_2_tbl

# Step 2 - Visualize

sales_by_year_cat_2_tbl %>%
    
    # Set up x, y, fill 
    ggplot(aes(x = year, y = sales, fill = category_2)) +
    
    # Geometries
    geom_col() +
    geom_smooth(method = "lm", se = FALSE) +
    
    # Facet
    facet_wrap(~ category_2, ncol = 3, scales = "free_y") +
    
    # Formatting
    theme_tq() +
    scale_fill_tq() +
    scale_y_continuous(labels = scales::dollar) +
    labs(
        title = "Revenue by Year and Category 2",
        subtitle = "Each product category has an upward trend",
        x = "",
        y = "Revenue",
        fill = "Product Secondary Category"
    )


# 7.0 Writing Files ----

fs::dir_create("00_data/bike_sales/data_wrangled_student")

# 7.1 Excel ----

bike_orderlines_wrangled_tbl %>%
    write_xlsx("00_data/bike_sales/data_wrangled_student/bike_orderlines.xlsx")


# 7.2 CSV ----

bike_orderlines_wrangled_tbl %>%
    write_csv("00_data/bike_sales/data_wrangled_student/bike_orderlines.csv")


# 7.3 RDS ----

bike_orderlines_wrangled_tbl %>%
    write_rds("00_data/bike_sales/data_wrangled_student/bike_orderlines.rds")


```

#  `r fa("laptop-code", fill = "black")` Challenge

Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum.
Curabitur pretium tincidunt lacus. Nulla gravida orci a odio. Nullam varius, turpis et commodo pharetra, est eros bibendum elit, nec luctus magna felis sollicitudin mauris. Integer in mauris eu nibh euismod gravida. Duis ac tellus et risus vulputate vehicula. Donec lobortis risus a elit. Etiam tempor. Ut ullamcorper, ligula eu tempor congue, eros est euismod turpis, id tincidunt sapien risus a quam. Maecenas fermentum consequat mi. Donec fermentum. Pellentesque malesuada nulla a mi. Duis sapien sem, aliquet nec, commodo eget, consequat quis, neque. Aliquam faucibus, elit ut dictum aliquet, felis nisl adipiscing sapien, sed malesuada diam lacus eget erat. Cras mollis scelerisque nunc. Nullam arcu. Aliquam consequat. Curabitur augue lorem, dapibus quis, laoreet et, pretium ac, nisi. Aenean magna nisl, mollis quis, molestie eu, feugiat in, orci. In hac habitasse platea dictumst.