[
["welcome.html", "DATA SCIENCE Course script Module from our certificate program Welcome", " DATA SCIENCE Course script Module from our certificate program Joschka Schwarz 2020-04-10 Welcome This script are the class notes used in the NIT Data Science course. It will teach you how to program in R, with hands-on examples for business analytics. It is written for non-programmers to provide a friendly introduction to the R language. You’ll learn how to load data, assemble and disassemble data objects, navigate R’s environment system, write your own functions, and use all of R’s programming tools. "],
["preface.html", "Preface", " Preface This book will teach you how to program in R. You’ll go from loading data to writing your own functions (which will outperform the functions of other R users). But this is not a typical introduction to R. I want to help you become a data scientist, as well as a computer scientist, so this book will focus on the programming skills that are most related to data science. The chapters in the book are arranged according to three practical projects–given that they’re fairly substantial projects, they span multiple chapters. I chose these projects for two reasons. First, they cover the breadth of the R language. You will learn how to load data, assemble and disassemble data objects, navigate R’s environment system, write your own functions, and use all of R’s programming tools, such as if else statements, for loops, S3 classes, R’s package system, and R’s debugging tools. The projects will also teach you how to write vectorized R code, a style of lightning-fast code that takes advantage of all of the things R does best. But, more importantly, the projects will teach you how to solve the logistical problems of data science—and there are many logistical problems. When you work with data, you will need to store, retrieve, and manipulate large sets of values without introducing errors. As you work through the book, I will teach you not just how to program with R, but how to use the programming skills to support your work as a data scientist. Not every programmer needs to be a data scientist, so not every programmer will find this book useful. You will find this book helpful if you’re in one of the following categories: You already use R as a statistical tool, but you would like to learn how to write your own functions and simulations with R. You would like to teach yourself how to program, and you see the sense of learning a language related to data science. One of the biggest surprises in this book is that I do not cover traditional applications of R, such as models and graphs; instead, I treat R purely as a programming language. Why this narrow focus? R is designed to be a tool that helps scientists analyze data. It has many excellent functions that make plots and fit models to data. As a result, many statisticians learn to use R as if it were a piece of software—they learn which functions do what they want, and they ignore the rest. This is an understandable approach to learning R. Visualizing and modeling data are complicated skills that require a scientist’s full attention. It takes expertise, judgement, and focus to extract reliable insights from a data set. I would not recommend that any data scientist distract herself with computer programming until she feels comfortable with the basic theory and practice of her craft. If you would like to learn the craft of data science, I recommend the book R for Data Science, my companion volume to this book, co-written with Hadley Wickham. However, learning to program should be on every data scientist’s to-do list. Knowing how to program will make you a more flexible analyst and augment your mastery of data science in every way. My favorite metaphor for describing this was introduced by Greg Snow on the R help mailing list in May 2006. Using functions in R is like riding a bus. Writing functions in R is like driving a car. Busses are very easy to use, you just need to know which bus to get on, where to get on, and where to get off (and you need to pay your fare). Cars, on the other hand, require much more work: you need to have some type of map or directions (even if the map is in your head), you need to put gas in every now and then, you need to know the rules of the road (have some type of drivers license). The big advantage of the car is that it can take you a bunch of places that the bus does not go and it is quicker for some trips that would require transferring between busses. Using this analogy, programs like SPSS are busses, easy to use for the standard things, but very frustrating if you want to do something that is not already preprogrammed. R is a 4-wheel drive SUV (though environmentally friendly) with a bike on the back, a kayak on top, good walking and running shoes in the passenger seat, and mountain climbing and spelunking gear in the back. R can take you anywhere you want to go if you take time to learn how to use the equipment, but that is going to take longer than learning where the bus stops are in SPSS. - Greg Snow Greg compares R to SPSS, but he assumes that you use the full powers of R; in other words, that you learn how to program in R. If you only use functions that preexist in R, you are using R like SPSS: it is a bus that can only take you to certain places. This flexibility matters to data scientists. The exact details of a method or simulation will change from problem to problem. If you cannot build a method tailored to your situation, you may find yourself tempted to make unrealistic assumptions just so you can use an ill-suited method that already exists. This book will help you make the leap from bus to car. I have written it for beginning programmers. I do not talk about the theory of computer science—there are no discussions of big O() and little o() in these pages. Nor do I get into advanced details such as the workings of lazy evaluation. These things are interesting if you think of computer science at the theoretical level, but they are a distraction when you first learn to program. Instead, I teach you how to program in R with three concrete examples. These examples are short, easy to understand, and cover everything you need to know. I have taught this material many times in my job as Master Instructor at RStudio. As a teacher, I have found that students learn abstract concepts much faster when they are illustrated by concrete examples. The examples have a second advantage, as well: they provide immediate practice. Learning to program is like learning to speak another language—you progress faster when you practice. In fact, learning to program is learning to speak another language. You will get the best results if you follow along with the examples in the book and experiment whenever an idea strikes you. The book is a companion to R for Data Science. In that book, Hadley Wickham and I explain how to use R to make plots, model data, and write reports. That book teaches these tasks as data-science skills, which require judgement and expertise—not as programming exercises, which they also are. This book will teach you how to program in R. It does not assume that you have mastered the data-science skills taught in R for Data Science (nor that you ever intend to). However, this skill set amplifies that one. And if you master both, you will be a powerful, computer-augmented data scientist, fit to command a high salary and influence scientific dialogue. "],
["introduction-to-r.html", "0.1 Introduction to R", " 0.1 Introduction to R 0.1.1 What is R? R is a powerful statistical environment and programming language for the analysis and visualization of data … 0.1.2 Why using R? Complete statistical environment and programming language Efficient functions and data structures for data analysis Powerful graphics Access to fast growing number of analysis packages Technical advantages: free, open-source, available for all OSs It’s easy to get distracted by Tableau and PowerBI’s visuals, but when it comes to making business decisions, your organization needs to be able to take actions. This is where R Shiny is lightyears ahead of the other tools - R Shiny is a powerful ecosystem for business + data science + apps. "],
["prerquisites.html", "0.2 Prerquisites", " 0.2 Prerquisites There is no prerequisite knowledge needed in R Programming, Data Science, or Machine Learning. "],
["conventions-used-in-this-book.html", "0.3 Conventions Used in This Book", " 0.3 Conventions Used in This Book The following typographical conventions are used in this book: Italic:: Indicates new terms, URLs, email addresses, filenames, and file extensions. Constant width:: Used for program listings, as well as within paragraphs to refer to program elements such as variable or function names, databases, data types, environment variables, statements, and keywords. Constant width bold:: Shows commands or other text that should be typed literally by the user. Constant width italic:: Shows text that should be replaced with user-supplied values or by values determined by context. To comment or ask technical questions about this book, please file an issue at github.com/rstudio-education/hopr. "],
["getting-started.html", "Chapter 1 R &amp; RStudio", " Chapter 1 R &amp; RStudio On the following sites you’ll find information about how to install the language R and the IDE RStudio. "],
["installing-r-rstudio-ide.html", "1.1 Installing R &amp; RStudio IDE", " 1.1 Installing R &amp; RStudio IDE 1.1.1 Interactively Go to the following link and follow the instructions to install R and the IDE RStudio Interactive Shinyapp Install R &amp; RStudio IDE 1.1.2 Manually Video instructions to install RStudio (Download link below) Download https://cloud.r-project.org Video instructions to install RStudio (Download link below) Download https://rstudio.com/products/rstudio/download/ Video instructions to install R packages Installing Packages # install package from CRAN install.packages(&quot;dplyr&quot;) Loading packages # load the package to use in the current R session library(&quot;packagename&quot;) # use a particular function within a package without loading the package packagename::functionname "],
["running-r-code-stolen-from-r4ds.html", "1.2 Running R code (stolen from R4DS)", " 1.2 Running R code (stolen from R4DS) The previous section showed you a couple of examples of running R code. Code in the book looks like this: 1 + 2 ## [1] 3 If you run the same code in your local console, it will look like this: &gt; 1 + 2 [1] 3 There are two main differences. In your console, you type after the &gt;, called the prompt; we don’t show the prompt in the book. In the book, output is commented out with #&gt;; in your console it appears directly after your code. These two differences mean that if you’re working with an electronic version of the book, you can easily copy code out of the book and into the console. Throughout the book we use a consistent set of conventions to refer to code: * Functions are in a code font and followed by parentheses, like sum(), or mean(). * Other R objects (like data or function arguments) are in a code font, without parentheses, like flights or x. If we want to make it clear what package an object comes from, we’ll use the package name followed by two colons, like dplyr::mutate(), or nycflights13::flights. This is also valid R code. "],
["exercise-1.html", "1.3 Exercise 1", " 1.3 Exercise 1 Identify what working directory you are working out of. Create a folder on your computer titled datascience. Within R, set your working directory to this folder. Solution Identify what working directory you are working out of. getwd() #&gt; [1] &quot;/Users/j.schwarz/NIT/&quot; Create a folder on your computer titled datascience. Within R, set your working directory to this folder. setwd(&quot;/Users/j.schwarz/NIT/datascience&quot;) "],
["exercise-2.html", "1.4 Exercise 2", " 1.4 Exercise 2 dplyr is an extremely popular package for common data transformation activities and is available from CRAN. Perform the following tasks: Install the dplyr package. Load the dplyr package. Access the help documentation for the dplyr package. Check out the vignette(s) for dplyr Solution Install the tidyverse package. install.packages(&quot;tidyverse&quot;) Load the tidyverse package. library(tidyverse) "],
["working-with-rstudio-setup-customization.html", "1.5 Working with RStudio / Setup &amp; Customization", " 1.5 Working with RStudio / Setup &amp; Customization Essential basics. The rest will be explained with the business examples never saving / loading .Rdata on exit / on startup (problem to recreate reproducible code) "],
["github-github-desktop.html", "Chapter 2 GitHub &amp; GitHub Desktop", " Chapter 2 GitHub &amp; GitHub Desktop Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum. Curabitur pretium tincidunt lacus. Nulla gravida orci a odio. Nullam varius, turpis et commodo pharetra, est eros bibendum elit, nec luctus magna felis sollicitudin mauris. Integer in mauris eu nibh euismod gravida. Duis ac tellus et risus vulputate vehicula. Donec lobortis risus a elit. Etiam tempor. Ut ullamcorper, ligula eu tempor congue, eros est euismod turpis, id tincidunt sapien risus a quam. Maecenas fermentum consequat mi. Donec fermentum. Pellentesque malesuada nulla a mi. Duis sapien sem, aliquet nec, commodo eget, consequat quis, neque. Aliquam faucibus, elit ut dictum aliquet, felis nisl adipiscing sapien, sed malesuada diam lacus eget erat. Cras mollis scelerisque nunc. Nullam arcu. Aliquam consequat. Curabitur augue lorem, dapibus quis, laoreet et, pretium ac, nisi. Aenean magna nisl, mollis quis, molestie eu, feugiat in, orci. In hac habitasse platea dictumst. "],
["create-a-free-github-account-.html", "2.1 Create a free github account.", " 2.1 Create a free github account. Website https://github.com/ "],
["download-and-install-github-desktop.html", "2.2 Download and install github desktop", " 2.2 Download and install github desktop Download https://desktop.github.com FIGURE 2.1: Project structure example in RStudio. "],
["create-your-own-labjournal.html", "2.3 Create your own LabJournal", " 2.3 Create your own LabJournal Fork, or download …. LabJournalTemplate "],
["session-01-01.html", "Chapter 3 Introduction to the tidyverse", " Chapter 3 Introduction to the tidyverse (#fig:data-science-workflow_1)Project structure example in RStudio. (#fig:data-science-workflow_2)Typical Tidyverse Workflow The tidyverse is a collection of R packages developed by RStudio’s chief scientist Hadley Wickham. These packages work well together as part of larger data analysis pipeline. To learn more about these tools and how they work together, read R for data science. The following tutorial will introduce some basic functions in tidyverse for structuring and analyzing datasets. This is the first in a three-part series on cleaning data to visualize it in R using the tidyverse. "],
["import-loading-data-with-readr-readxl.html", "3.1 IMPORT - Loading data with readr / readxl", " 3.1 IMPORT - Loading data with readr / readxl Before you can manipulate data with R, you need to import the data into R’s memory, or build a connection to the data that R can use to access the data remotely. How you import your data will depend on the format of the data. The most common way to store small data sets is as a plain text file. Data may also be stored in a proprietary format associated with a specific piece of software, such as SAS, SPSS, or Microsoft Excel. Data used on the internet is often stored as a JSON or XML file. Large data sets may be stored in a database or a distributed storage system. When you import data into R, R stores the data in your computer’s RAM while you manipulate it. This creates a size limitation: truly big data sets should be stored outside of R in a database or distributed storage system. You can then create a connection to the system that R can use to access the data without bringing the data into your computer’s RAM. The tidyverse offers the following packages for importing data: readr for reading flat files like .csv files readxl for .xls and .xlsx sheets. haven for SPSS, Stata, and SAS data. googledrive to interact with files on Google Drive from R. .column{ float: left; width: 25%; padding: 5px; } .row::after{ content: \"\"; clear: both; display: table; } .column{ float: left; width: 25%; padding: 5px; } .row::after{ content: \"\"; clear: both; display: table; } Click on the images to get more information There are a handful of other packages that are not in the tidyverse, but are tidyverse-adjacent. They are very useful for importing data from other sources: jsonlite for JSON. xml2 for XML. httr for web APIs. rvest for web scraping. DBI for relational databases. To connect to a specific database, you’ll need to pair DBI with a specific backend like RSQLite, RPostgres, or odbc. Learn more at https://db.rstudio.com. Example # Loading data (can also be achieved by clicking on &quot;Import Dataset &gt; From Text (readr)&quot; in the upper right corner) library(readr) dataset_tbl &lt;- read_csv(&quot;data.csv&quot;)) # Writing data write_csv(dataset_tbl, &quot;data.csv&quot;) # Saving in csv (or tsv) does mean you loose information about the type of data in particular columns. You can avoid this by using write_rds() and read_rds() to read/write objects in R binary rds format. write_rds(dataset_tbl, &quot;data.rds&quot;) "],
["pipes.html", "3.2 Pipes", " 3.2 Pipes Pipes are a powerful tool for clearly expressing a sequence of multiple operations. You will be using the “pipe”-operator %&gt;% throughout this class. The “pipe” is from the magrittr package. The point of the pipe is to help you write code in a way that is easier to read and understand. It makes your code more readable by structuring sequences of data operations left-to-right (as opposed to from the inside and out). The pipe makes your code read more like a sentence, branching from left to right. You can read it as a series of imperative statements: group, then summarise, then filter. As suggested by this reading, a good way to pronounce %&gt;% when reading code is “then”. Mathematically it can be expressed like the following: x %&gt;% f is equivalent to f(x) x %&gt;% f(y) is equivalent to f(x, y) x %&gt;% f %&gt;% g %&gt;% h is equivalent to h(g(f(x))) Instead of writing this: data &lt;- iris data &lt;- head(data, n=3) you can write the code like this: # The easiest way to get magrittr is to load the whole tidyverse: library(&quot;tidyverse&quot;) # Alternatively, load just magrittr: library(&quot;magrittr&quot;) iris %&gt;% head(n=3) Example When coupling several function calls with the pipe-operator, the benefit will become more apparent. Consider this pseudo example: "],
["tibbles.html", "3.3 Tibbles", " 3.3 Tibbles Throughout this class we work with “tibbles” instead of R’s traditional data.frame. Tibbles are data frames, but they tweak some older behaviours to make life a little easier. R is an old language, and some things that were useful 10 or 20 years ago now get in your way. In most places, the term tibble and data frame will be used interchangeably. tibble is one of the unifying features of tidyverse, it is a better data.frame realization, objects data.frame can be coerced to tibble using as_tibble() When you print a tibble: * all columns that fit the screen are shown, * first 10 rows are shown, * data type for each column is shown. tibble( x = 1, # recycling y = runif(50), z = x + y^2, outcome = rnorm(50) ) as_tibble(cars) Subsetting tibbles vehicles &lt;- as_tibble(cars[1:5,]) vehicles[[&#39;speed&#39;]] vehicles[[1]] vehicles$speed # Using placeholders vehicles %&gt;% .$dist vehicles %&gt;% .[[&#39;dist&#39;]] vehicles %&gt;% .[[2]] "],
["tidy-reshaping-your-data-with-tidyr.html", "3.4 TIDY - Reshaping your data with tidyr", " 3.4 TIDY - Reshaping your data with tidyr The Concept of Tidy Data each and every observation is represented as exactly one row, each and every variable is represented by exactly one column, thus each data table cell contains only one value. FIGURE 3.1: The concept of tidy data Usually data are untidy in only one way. However, if you are unlucky, they are really untidy and thus a pain to work with… For the following example is the Diamonds Dataset used from the ggplot2 package. gather(): Use, if some of your column names are actually values of a variable diamonds2 ## # A tibble: 5 x 3 ## cut `2008` `2009` ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 Ideal 326 332 ## 2 Premium 326 332 ## 3 Good 237 333 ## 4 Premium 334 340 ## 5 Good 335 341 diamonds2 %&gt;% gather(`2008`, `2009`, key = &#39;year&#39;, value = &#39;price&#39;) ## # A tibble: 10 x 3 ## cut year price ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 Ideal 2008 326 ## 2 Premium 2008 326 ## 3 Good 2008 237 ## 4 Premium 2008 334 ## 5 Good 2008 335 ## 6 Ideal 2009 332 ## 7 Premium 2009 332 ## 8 Good 2009 333 ## 9 Premium 2009 340 ## 10 Good 2009 341 spread(): Use, if some of your observations are scattered across many rows bijou3 bijou3 %&gt;% spread(key=dimension, value=measurement) %&gt;% head(n = 5) "],
["transform-data-transformations-with-dplyr.html", "3.5 TRANSFORM - Data Transformations with dplyr", " 3.5 TRANSFORM - Data Transformations with dplyr Often you’ll need to create some new variables or summaries, or maybe you just want to rename the variables or reorder the observations in order to make the data a little easier to work with. dplyr is a grammar of data manipulation, providing a consistent set of verbs that help you solve the most common data manipulation challenges. The following five key dplyr functions allow you to solve the vast majority of your data manipulation challenges: filter() picks cases based on their values. So it can be used for selecting the relevant rows. diamonds %&gt;% filter(cut == &#39;Ideal&#39; | cut == &#39;Premium&#39;, carat &gt;= 0.23) %&gt;% head(5) ## # A tibble: 5 x 10 ## carat cut color clarity depth table price x y z ## &lt;dbl&gt; &lt;ord&gt; &lt;ord&gt; &lt;ord&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 0.23 Ideal E SI2 61.5 55 326 3.95 3.98 2.43 ## 2 0.290 Premium I VS2 62.4 58 334 4.2 4.23 2.63 ## 3 0.23 Ideal J VS1 62.8 56 340 3.93 3.9 2.46 ## 4 0.31 Ideal J SI2 62.2 54 344 4.35 4.37 2.71 ## 5 0.32 Premium E I1 60.9 58 345 4.38 4.42 2.68 arrange() changes the ordering of the rows diamonds %&gt;% arrange(cut, carat, desc(price)) ## # A tibble: 53,940 x 10 ## carat cut color clarity depth table price x y z ## &lt;dbl&gt; &lt;ord&gt; &lt;ord&gt; &lt;ord&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 0.22 Fair E VS2 65.1 61 337 3.87 3.78 2.49 ## 2 0.23 Fair G VVS2 61.4 66 369 3.87 3.91 2.39 ## 3 0.25 Fair F SI2 54.4 64 1013 4.3 4.23 2.32 ## 4 0.25 Fair D VS1 61.2 55 563 4.09 4.11 2.51 ## 5 0.25 Fair E VS1 55.2 64 361 4.21 4.23 2.33 ## 6 0.27 Fair E VS1 66.4 58 371 3.99 4.02 2.66 ## 7 0.290 Fair F SI1 55.8 60 1776 4.48 4.41 2.48 ## 8 0.290 Fair D VS2 64.7 62 592 4.14 4.11 2.67 ## 9 0.3 Fair D IF 60.5 57 1208 4.47 4.35 2.67 ## 10 0.3 Fair E VVS2 51 67 945 4.67 4.62 2.37 ## # … with 53,930 more rows The NAs always end up at the end of the rearranged tibble. select() picks variables based on their names diamonds %&gt;% select(color, clarity, x:z) %&gt;% head(n = 5) ## # A tibble: 5 x 5 ## color clarity x y z ## &lt;ord&gt; &lt;ord&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 E SI2 3.95 3.98 2.43 ## 2 E SI1 3.89 3.84 2.31 ## 3 E VS1 4.05 4.07 2.31 ## 4 I VS2 4.2 4.23 2.63 ## 5 J SI2 4.34 4.35 2.75 Exclusive select: diamonds %&gt;% select(-(x:z)) %&gt;% head(n = 5) ## # A tibble: 5 x 7 ## carat cut color clarity depth table price ## &lt;dbl&gt; &lt;ord&gt; &lt;ord&gt; &lt;ord&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; ## 1 0.23 Ideal E SI2 61.5 55 326 ## 2 0.21 Premium E SI1 59.8 61 326 ## 3 0.23 Good E VS1 56.9 65 327 ## 4 0.290 Premium I VS2 62.4 58 334 ## 5 0.31 Good J SI2 63.3 58 335 Select helpers use everything() to bring some columns to the front: bijou %&gt;% select(x:z, everything()) %&gt;% head(n = 5) rename() diamonds %&gt;% rename(var_x = x) %&gt;% head(n = 5) ## # A tibble: 5 x 10 ## carat cut color clarity depth table price var_x y z ## &lt;dbl&gt; &lt;ord&gt; &lt;ord&gt; &lt;ord&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 0.23 Ideal E SI2 61.5 55 326 3.95 3.98 2.43 ## 2 0.21 Premium E SI1 59.8 61 326 3.89 3.84 2.31 ## 3 0.23 Good E VS1 56.9 65 327 4.05 4.07 2.31 ## 4 0.290 Premium I VS2 62.4 58 334 4.2 4.23 2.63 ## 5 0.31 Good J SI2 63.3 58 335 4.34 4.35 2.75 mutate() adds new variables that are functions of existing variables. transmute() diamonds %&gt;% mutate(p = x + z, q = p + y) %&gt;% select(-(depth:price)) %&gt;% head(n = 5) ## # A tibble: 5 x 9 ## carat cut color clarity x y z p q ## &lt;dbl&gt; &lt;ord&gt; &lt;ord&gt; &lt;ord&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 0.23 Ideal E SI2 3.95 3.98 2.43 6.38 10.4 ## 2 0.21 Premium E SI1 3.89 3.84 2.31 6.2 10.0 ## 3 0.23 Good E VS1 4.05 4.07 2.31 6.36 10.4 ## 4 0.290 Premium I VS2 4.2 4.23 2.63 6.83 11.1 ## 5 0.31 Good J SI2 4.34 4.35 2.75 7.09 11.4 diamonds %&gt;% transmute(carat, cut, sum = x + y + z) %&gt;% head(n = 5) ## # A tibble: 5 x 3 ## carat cut sum ## &lt;dbl&gt; &lt;ord&gt; &lt;dbl&gt; ## 1 0.23 Ideal 10.4 ## 2 0.21 Premium 10.0 ## 3 0.23 Good 10.4 ## 4 0.290 Premium 11.1 ## 5 0.31 Good 11.4 group_by() and summarize() reduces multiple values down to a single summary diamonds %&gt;% group_by(cut) %&gt;% summarize(max_price = max(price), mean_price = mean(price), min_price = min(price)) ## # A tibble: 5 x 4 ## cut max_price mean_price min_price ## &lt;ord&gt; &lt;int&gt; &lt;dbl&gt; &lt;int&gt; ## 1 Fair 18574 4359. 337 ## 2 Good 18788 3929. 327 ## 3 Very Good 18818 3982. 336 ## 4 Premium 18823 4584. 326 ## 5 Ideal 18806 3458. 326 "],
["lubridate.html", "3.6 Lubridate", " 3.6 Lubridate "],
["stringr.html", "3.7 Stringr", " 3.7 Stringr "],
["purrr.html", "3.8 Purrr", " 3.8 Purrr needed here? "],
["business-case-sales-analysis.html", "Chapter 4 Business case - Sales Analysis", " Chapter 4 Business case - Sales Analysis Sales Analysis Overview Overall goals Introductory words … You are a data scientist. Your assignment is to … study the products … looking for opportunities to sell new producgts better serve the customer better market the products justify it by data … Goals for this session Get your hands into R with a real world situation Analyze Sales over time of products sold through the Olist Store Sales by Year Sales by secondary product category Steps Import flatfiles databases scrape Wrangle data examine data clean data join data Visualize data Context Olist is the largest department store in Brazilian marketplaces. Olist connects small businesses from all over Brazil to channels without hassle and with a single contract. Those merchants are able to sell their products through the Olist Store and ship them directly to the customers using Olist logistics partners. See more on their website: www.olist.com After a customer purchases the product from Olist Store a seller gets notified to fulfill that order. Once the customer receives the product, or the estimated delivery date is due, the customer gets a satisfaction survey by email where he can give a note for the purchase experience and write down some comments. FIGURE 4.1: Project structure example in RStudio. "],
["theory-background.html", "4.1 Theory / Background", " 4.1 Theory / Background 4.1.1 Transactional data FIGURE 4.2: Project structure example in RStudio. The Entity Relationship Diagram (ERD) Types of database relationships (1-to-1, 1-to-many,many-to-many) 4.1.2 data schema The data is divided in multiple datasets for better understanding and organization. Please refer to the following data schema when working with it: FIGURE 4.3: Project structure example in RStudio. insert explanation and screenshots of the excel files The dataset has information of 100k orders from 2016 to 2018 made at multiple marketplaces in Brazil. Its features allows viewing an order from multiple dimensions: from order status, price, payment and freight performance to customer location, product attributes and finally reviews written by customers. In addition a geolocation dataset that relates Brazilian zip codes to lat/lng coordinates is released. This is real commercial data, it has been anonymised, and references to the companies and partners in the review text have been replaced with the names of Game of Thrones great houses. Attention An order might have multiple items. Each item might be fulfilled by a distinct seller. All text identifying stores and partners where replaced by the names of Game of Thrones great houses. It was also a Marketing Funnel Dataset released. Both datasets may be joined to see an order from Marketing perspective! FIGURE 4.4: Project structure example in RStudio. Inspiration Here are some inspiration for possible outcomes from this dataset. NLP: This dataset offers a supreme environment to parse out the reviews text through its multiple dimensions. Clustering: Some customers didn’t write a review. But why are they happy or mad? Sales Prediction: With purchase date information you’ll be able to predict future sales. Delivery Performance: You will also be able to work through delivery performance and find ways to optimize delivery times. Product Quality: Enjoy yourself discovering the products categories that are more prone to customer insatisfaction. Feature Engineering: Create features from this rich dataset or attach some external public information to it. "],
["project-setup.html", "4.2 Project Setup", " 4.2 Project Setup 4.2.1 Project structure Download DS_business_case.zip FIGURE 4.5: Project structure example in RStudio. 4.2.2 Installing Packages Download session_01_install_pkgs.R package deoendencies c operatior stands for combining elements control + enter or cmd + enter global environment output to the screen (print) comments (not being added to the cvector) explanation of the right hand corner (packages, etc) Errors: what to do in case of errors during installation (maybe Rtools is needed, windows users) Doy you want to install from source the packages which need compilation 4.2.3 Checkpoint Key Checks at this Point User Library Verification Directory Structure Verification "],
["import.html", "4.3 Import", " 4.3 Import 4.3.1 Setup (Template File) Download the template we will be using for the analysis Download s01-02_sales_analysis.R The content of the file looks like this: # datascience at NIT ------------------------------------------------------ # 1.0 Load libraries ---- library(tidyverse) library(lubridate) library(tidyquant) library(readxl) library(writexl) # 2.0 Importing Files ---- # 3.0 Examining Data ---- # 4.0 Joining Data ---- # 5.0 Wrangling Data ---- # 6.0 Business Insights ---- # 6.1 Sales by Year ---- # Step 1 - Manipulate # Step 2 - Visualize # 6.2 Sales by Year and Category 2 ---- # Step 1 - Manipulate # Step 2 - Visualize # 7.0 Writing Files ---- # 7.1 Excel ---- # 7.2 CSV ---- # 7.3 RDS ---- Add some hints (toc, environment, …) 4.3.2 Import 4.3.2.1 flatfiles library(readr) library(readxl) library(odbc) library(RSQLite) importing excel files: readr for our csv files for xlsx files read_excel() Pro Tip Explain the ? in front of functions (contr + enter). Use ?function_name to get the help documentation on a function. Usage and arguments section. Pro Tip Use tab complete to quickly complete function names as well as file pathes Expplaing assignment Explaing tibble ( special structure that stores data) Environment variable now, can be viewd by clicking on it Excel files and local databases data.frames, lists, vectors, … data types, basics 4.3.2.2 web scraping library(httr) library(rvest) library(RSelenium) Screen scraping and jsons via API 4.3.3 Checkpoint 4.3.4 Examine regular print (output tibble to console) open data window (view() function), filtering etc. glimpse() function (prints it out in a transpose fashoin) –&gt; Objective: Combine the three tibbles into one that can be analyzed 4.3.5 Cleaning and joining data library(dplyr) library(tidyr) library(tidyverse) left_join, rbind, filtering, naming, pipe operator, … group_by, summarize 4.3.6 Checkpoint 4.3.7 Visualizing data with ggplot2 library(ggplot2) different geometries saving files 4.3.8 Checkpoint "],
["session-01-challenge.html", "4.4 Session 01 Challenge", " 4.4 Session 01 Challenge Download sales_analysis.rmd Rmarkdown file with instructions! # --- # title: &quot;Week 2 Challenge&quot; # author: &quot;Business Science&quot; # date: &quot;12/30/2018&quot; # output: # html_document: # toc: TRUE # theme: flatly # highlight: tango # code_folding: show # --- # # ```{r setup, include=FALSE} # knitr::opts_chunk$set( # echo = TRUE # ) # ``` # # # Challenge Summary # # This is a short challenge to begin applying what you are learning to the problem at hand. You will go through a series of questions related to the course project goals: # # 1. Coming up with a new product idea, and # # 2. Segmenting the customer-base # # # Objectives # # 1. Apply `dplyr` and `tidyr` functions to answer questions related to the course projects. # # 2. Gain exposure to `rmarkdown` # # # Data # # To read the data, make sure that the paths point to the appropriate data sets. Saving the file in the main directory should enable the paths to be detected correctly. # # ```{r, message=FALSE, warning=FALSE} # # Load libraries # library(tidyverse) # ``` # # ```{r} # # Read bike orderlines data # path_bike_orderlines &lt;- &quot;00_data/bike_sales/data_wrangled/bike_orderlines.rds&quot; # bike_orderlines_tbl &lt;- read_rds(path_bike_orderlines) # # glimpse(bike_orderlines_tbl) # ``` # # ```{r} # # Read bikes data # path_bikes &lt;- &quot;00_data/bike_sales//data_raw/bikes.xlsx&quot; # bikes_tbl &lt;- readxl::read_excel(path_bikes) # # glimpse(bikes_tbl) # ``` # # # Questions # # # # ## 1. What are the unique categories of products? (Difficulty = Low) # # - Begin with `bike_orderlines_tbl` # - Use `distinct()` to evaluate # # Review Primary Product Category (`category_1`). # # ```{r} # # ``` # # # Review Secondary Product Category (`category_2`). # # ```{r} # # ``` # # Review Frame Material (`frame_material`). # # ```{r} # # ``` # # # ## 2. Which product categories have the most sales? (Difficulty = Medium) # # - Select appropriate columns from `bike_orderlines_tbl` # - Group and summarize the data calling the new column `Sales`. Make sure to ungroup. # - Arrange descending by `Sales` # - Rename column names to `Primary Category`, `Secondary Category`, or `Frame Material` (as appropriate). # - Format the Sales as `dollar()` # # Review Primary Product Category (`category_1`). # # ```{r} # # # ``` # # Review Secondary Product Category (`category_2`). # # ```{r} # # # ``` # # # Review Frame Material (`frame_material`). # # ```{r} # # "],
["session-01-solution.html", "4.5 Session 01 Solution", " 4.5 Session 01 Solution Download session_01_solution.R FIGURE 4.6: Project structure example in RStudio. # DS4B 101-R: R FOR BUSINESS ANALYSIS ---- # JUMPSTART: First Sales Analysis ---- # 1.0 Load libraries ---- # Work horse packages library(tidyverse) library(lubridate) # theme_tq() library(tidyquant) # Excel Files library(readxl) library(writexl) # 2.0 Importing Files ---- ?read_excel() bikes_tbl &lt;- read_excel(path = &quot;00_data/bike_sales/data_raw/bikes.xlsx&quot;) bikeshops_tbl &lt;- read_excel(&quot;00_data/bike_sales/data_raw/bikeshops.xlsx&quot;) orderlines_tbl &lt;- read_excel(&quot;00_data/bike_sales/data_raw/orderlines.xlsx&quot;) names(orderlines_tbl)[1] &lt;- &quot;X__1&quot; # 3.0 Examining Data ---- bikes_tbl glimpse(bikes_tbl) bikeshops_tbl orderlines_tbl # 4.0 Joining Data ---- ?left_join orderlines_tbl bikes_tbl left_join(orderlines_tbl, bikes_tbl, by = c(&quot;product.id&quot; = &quot;bike.id&quot;)) bike_orderlines_joined_tbl &lt;- orderlines_tbl %&gt;% left_join(bikes_tbl, by = c(&quot;product.id&quot; = &quot;bike.id&quot;)) %&gt;% left_join(bikeshops_tbl, by = c(&quot;customer.id&quot; = &quot;bikeshop.id&quot;)) bike_orderlines_joined_tbl bike_orderlines_joined_tbl %&gt;% glimpse() # 5.0 Wrangling Data ---- bike_orderlines_wrangled_tbl &lt;- bike_orderlines_joined_tbl %&gt;% # Separate description into category.1, category.2, and frame.material separate(description, into = c(&quot;category.1&quot;, &quot;category.2&quot;, &quot;frame.material&quot;), sep = &quot; - &quot;, remove = TRUE) %&gt;% # Separate location into city and state separate(location, into = c(&quot;city&quot;, &quot;state&quot;), sep = &quot;, &quot;, remove = FALSE) %&gt;% # price extended mutate(total.price = price * quantity) %&gt;% # Reorganize select(-X__1, -location) %&gt;% select(-ends_with(&quot;.id&quot;)) %&gt;% bind_cols(bike_orderlines_joined_tbl %&gt;% select(order.id)) %&gt;% # Reorder columns select(contains(&quot;date&quot;), contains(&quot;id&quot;), contains(&quot;order&quot;), quantity, price, total.price, everything()) %&gt;% # Renaming columns rename(order_date = order.date) %&gt;% set_names(names(.) %&gt;% str_replace_all(&quot;\\\\.&quot;, &quot;_&quot;)) bike_orderlines_wrangled_tbl %&gt;% glimpse() # 6.0 Business Insights ---- # 6.1 Sales by Year ---- # Step 1 - Manipulate sales_by_year_tbl &lt;- bike_orderlines_wrangled_tbl %&gt;% # Selecting columns to focus on and adding a year column select(order_date, total_price) %&gt;% mutate(year = year(order_date)) %&gt;% # Grouping by year, and summarizing sales group_by(year) %&gt;% summarize(sales = sum(total_price)) %&gt;% ungroup() %&gt;% # $ Format Text mutate(sales_text = scales::dollar(sales)) sales_by_year_tbl # Step 2 - Visualize sales_by_year_tbl %&gt;% # Setup canvas with year (x-axis) and sales (y-axis) ggplot(aes(x = year, y = sales)) + # Geometries geom_col(fill = &quot;#2c3e50&quot;) + geom_label(aes(label = sales_text)) + geom_smooth(method = &quot;lm&quot;, se = FALSE) + # Formatting theme_tq() + scale_y_continuous(labels = scales::dollar) + labs( title = &quot;Revenue by Year&quot;, subtitle = &quot;Upward trend&quot;, x = &quot;&quot;, y = &quot;Revenue&quot; ) # 6.2 Sales by Year and Category 2 ---- # Step 1 - Manipulate sales_by_year_cat_2_tbl &lt;- bike_orderlines_wrangled_tbl %&gt;% # Selecting columns and add a year select(order_date, total_price, category_2) %&gt;% mutate(year = year(order_date)) %&gt;% # Groupby and Summarize year and category 2 group_by(year, category_2) %&gt;% summarise(sales = sum(total_price)) %&gt;% ungroup() %&gt;% # Format $ Text mutate(sales_text = scales::dollar(sales)) sales_by_year_cat_2_tbl # Step 2 - Visualize sales_by_year_cat_2_tbl %&gt;% # Set up x, y, fill ggplot(aes(x = year, y = sales, fill = category_2)) + # Geometries geom_col() + geom_smooth(method = &quot;lm&quot;, se = FALSE) + # Facet facet_wrap(~ category_2, ncol = 3, scales = &quot;free_y&quot;) + # Formatting theme_tq() + scale_fill_tq() + scale_y_continuous(labels = scales::dollar) + labs( title = &quot;Revenue by Year and Category 2&quot;, subtitle = &quot;Each product category has an upward trend&quot;, x = &quot;&quot;, y = &quot;Revenue&quot;, fill = &quot;Product Secondary Category&quot; ) # 7.0 Writing Files ---- fs::dir_create(&quot;00_data/bike_sales/data_wrangled_student&quot;) # 7.1 Excel ---- bike_orderlines_wrangled_tbl %&gt;% write_xlsx(&quot;00_data/bike_sales/data_wrangled_student/bike_orderlines.xlsx&quot;) # 7.2 CSV ---- bike_orderlines_wrangled_tbl %&gt;% write_csv(&quot;00_data/bike_sales/data_wrangled_student/bike_orderlines.csv&quot;) # 7.3 RDS ---- bike_orderlines_wrangled_tbl %&gt;% write_rds(&quot;00_data/bike_sales/data_wrangled_student/bike_orderlines.rds&quot;) "],
["challenge.html", "Chapter 5 Challenge", " Chapter 5 Challenge Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum. Curabitur pretium tincidunt lacus. Nulla gravida orci a odio. Nullam varius, turpis et commodo pharetra, est eros bibendum elit, nec luctus magna felis sollicitudin mauris. Integer in mauris eu nibh euismod gravida. Duis ac tellus et risus vulputate vehicula. Donec lobortis risus a elit. Etiam tempor. Ut ullamcorper, ligula eu tempor congue, eros est euismod turpis, id tincidunt sapien risus a quam. Maecenas fermentum consequat mi. Donec fermentum. Pellentesque malesuada nulla a mi. Duis sapien sem, aliquet nec, commodo eget, consequat quis, neque. Aliquam faucibus, elit ut dictum aliquet, felis nisl adipiscing sapien, sed malesuada diam lacus eget erat. Cras mollis scelerisque nunc. Nullam arcu. Aliquam consequat. Curabitur augue lorem, dapibus quis, laoreet et, pretium ac, nisi. Aenean magna nisl, mollis quis, molestie eu, feugiat in, orci. In hac habitasse platea dictumst. "],
["session-01-02.html", "Chapter 6 Data visualization with ggplot", " Chapter 6 Data visualization with ggplot Every ggplot2 plot has three key components: data, A set of aesthetic mappings between variables in the data and visual properties, and At least one layer which describes how to render each observation. Layers are usually created with a geom function. "],
["visualize-introduction-to-visualization-in-ggplot2.html", "6.1 VISUALIZE - Introduction To Visualization In ggplot2", " 6.1 VISUALIZE - Introduction To Visualization In ggplot2 "],
["adding-complexity-to-visualizations.html", "6.2 Adding Complexity To Visualizations", " 6.2 Adding Complexity To Visualizations "],
["customizing-your-plots.html", "6.3 Customizing Your Plots", " 6.3 Customizing Your Plots "],
["business-case-sales-analysis-1.html", "Chapter 7 Business case - Sales Analysis", " Chapter 7 Business case - Sales Analysis "],
["challenge-1.html", "Chapter 8 Challenge ", " Chapter 8 Challenge "],
["content-1.html", "8.1 Content 1", " 8.1 Content 1 "],
["checkpoint-4.html", "8.2 Checkpoint", " 8.2 Checkpoint "],
["content-2.html", "8.3 Content 2", " 8.3 Content 2 "],
["checkpoint-5.html", "8.4 Checkpoint", " 8.4 Checkpoint "],
["session-02-challenge.html", "8.5 Session 02 - Challenge", " 8.5 Session 02 - Challenge "],
["session-02-solution.html", "8.6 Session 02 - Solution", " 8.6 Session 02 - Solution # # Challenge Summary # # This is a short challenge to begin applying what you are learning to the problem at hand. You will go through a series of questions related to the course project goals: # # 1. Coming up with a new product idea, and # # 2. Segmenting the customer-base # # # Objectives # # 1. Apply `dplyr` and `tidyr` functions to answer questions related to the course projects. # # 2. Gain exposure to `rmarkdown` # # # Data # # To read the data, make sure that the paths point to the appropriate data sets. Saving the file in the main directory should enable the paths to be detected correctly. # # ```{r, message=FALSE, warning=FALSE} # # Load libraries # library(tidyverse) # ``` # # ```{r} # # Read bike orderlines data # path_bike_orderlines &lt;- &quot;00_data/bike_sales/data_wrangled/bike_orderlines.rds&quot; # bike_orderlines_tbl &lt;- read_rds(path_bike_orderlines) # # glimpse(bike_orderlines_tbl) # ``` # # ```{r} # # Read bikes data # path_bikes &lt;- &quot;00_data/bike_sales//data_raw/bikes.xlsx&quot; # bikes_tbl &lt;- readxl::read_excel(path_bikes) # # glimpse(bikes_tbl) # ``` # # # Questions # # # # ## 1. What are the unique categories of products? (Difficulty = Low) # # - Begin with `bike_orderlines_tbl` # - Use `distinct()` to evaluate # # Review Primary Product Category (`category_1`). # # ```{r} # bike_orderlines_tbl %&gt;% # distinct(category_1) # ``` # # # Review Secondary Product Category (`category_2`). # # ```{r} # bike_orderlines_tbl %&gt;% # distinct(category_2) # ``` # # Review Frame Material (`frame_material`). # # ```{r} # bike_orderlines_tbl %&gt;% # distinct(frame_material) # ``` # # # ## 2. Which product categories have the most sales? (Difficulty = Medium) # # - Select appropriate columns from `bike_orderlines_tbl` # - Group and summarize the data calling the new column `Sales`. Make sure to ungroup. # - Arrange descending by `Sales` # - Rename column names to `Primary Category`, `Secondary Category`, or `Frame Material` (as appropriate). # - Format the Sales as `dollar()` # # Review Primary Product Category (`category_1`). # # ```{r} # bike_orderlines_tbl %&gt;% # # # Select columns # select(category_1, total_price) %&gt;% # # # Group and summarize # group_by(category_1) %&gt;% # summarize(sales = sum(total_price)) %&gt;% # ungroup() %&gt;% # # # Arrange descending # arrange(desc(sales)) %&gt;% # # # Rename columns # rename( # `Primary Category` = category_1, # Sales = sales # ) %&gt;% # # # Format dollar # mutate(Sales = Sales %&gt;% scales::dollar()) # # ``` # # Review Secondary Product Category (`category_2`). # # ```{r} # bike_orderlines_tbl %&gt;% # # # Select columns # select(category_2, total_price) %&gt;% # # # Group and summarize # group_by(category_2) %&gt;% # summarize(sales = sum(total_price)) %&gt;% # ungroup() %&gt;% # # # Arrange descending # arrange(desc(sales)) %&gt;% # # # Rename columns # rename( # `Secondary Category` = category_2, # Sales = sales # ) %&gt;% # # # Format dollar # mutate(Sales = Sales %&gt;% scales::dollar()) # # ``` # # # Review Frame Material (`frame_material`). # # ```{r} # bike_orderlines_tbl %&gt;% # # # Select columns # select(frame_material, total_price) %&gt;% # # # Group and summarize # group_by(frame_material) %&gt;% # summarize(sales = sum(total_price)) %&gt;% # ungroup() %&gt;% # # # Arrange descending # arrange(desc(sales)) %&gt;% # # # Rename columns # # Rename columns # rename( # `Frame Material` = frame_material, # Sales = sales # ) %&gt;% # # # Format dollar # mutate(Sales = Sales %&gt;% scales::dollar()) # # ``` # # ## 3. Do all combinations primary and secondary bike category contain both Aluminum and Carbon frame materials? (Difficulty = High) # # Hint - Use summarized sales values and `spread()` to identify gaps in frame materials. # # - Select `category_1`, `category_2`, `frame_material`, and `total_price` # - Summarize the data using group by, summarize and ungroup. # - Pivot the frame material and sales column into Alumninum and Carbon # - Fill `NA` values with zeros # - Add a `total_sales` column # - Arrange descending by `total_sales` # - Format all numbers as `dollar()` # - Rename all Columns: Primary Category, Secondary Category, Aluminum, Carbon, Total Sales # # ```{r} # bike_orderlines_tbl %&gt;% # # # Select columns # select(category_1, category_2, frame_material, total_price) %&gt;% # # # group_by, summarize, ungroup # group_by(category_1, category_2, frame_material) %&gt;% # summarize(sales = sum(total_price)) %&gt;% # ungroup() %&gt;% # # # spread # spread(key = frame_material, value = sales) %&gt;% # # # replace NA # replace_na(list(Aluminum = 0, Carbon = 0)) %&gt;% # # # Add Total Sales column # mutate(total_sales = Aluminum + Carbon) %&gt;% # # # Arrange descending # arrange(desc(total_sales)) %&gt;% # # # Format dollar # mutate( # Aluminum = scales::dollar(Aluminum), # Carbon = scales::dollar(Carbon), # total_sales = scales::dollar(total_sales) # ) %&gt;% # # # Rename columns # rename( # `Primary Category` = category_1, # `Secondary Category` = category_2, # `Total Sales` = total_sales # ) FIGURE 8.1: sakila db "],
["time-series.html", "Chapter 9 Time Series", " Chapter 9 Time Series library(tidyverse) library(lubridate) library(tidyquant) "],
["text-fundamentals.html", "Chapter 10 Text Fundamentals", " Chapter 10 Text Fundamentals library(stringr) Regex "],
["categorical-data.html", "Chapter 11 Categorical data", " Chapter 11 Categorical data library(forcats) "],
["functional-programming.html", "Chapter 12 Functional Programming", " Chapter 12 Functional Programming Learn to build functions Loops, apply-family library(purrr) "],
["exercise1.html", "12.1 Exercise1", " 12.1 Exercise1 Find the mean of 1:10. "],
["solution-2.html", "12.2 Solution", " 12.2 Solution Here is how. mean(1:10) ## [1] 5.5 "],
["exercise.html", "12.3 Exercise", " 12.3 Exercise Plot 1:10 in R. 12.3.1 Solution Here is the solution plot(1:10) "],
["machine-learning-concepts.html", "Chapter 13 Machine Learning concepts ", " Chapter 13 Machine Learning concepts "],
["customer-segmentation-with-k-means-clustering-umap.html", "13.1 Customer Segmentation with K-Means Clustering &amp; UMAP", " 13.1 Customer Segmentation with K-Means Clustering &amp; UMAP "],
["ml-linear-algorithms.html", "13.2 ML - Linear Algorithms", " 13.2 ML - Linear Algorithms "],
["ml-tree-based-algorithms.html", "13.3 ML - Tree Based Algorithms", " 13.3 ML - Tree Based Algorithms "],
["ml-preprocessing-svm.html", "13.4 ML - Preprocessing &amp; SVM", " 13.4 ML - Preprocessing &amp; SVM "],
["testing-the-models.html", "13.5 Testing the models", " 13.5 Testing the models "],
["session-04-challenge-company-segmentation-with-stock-prices.html", "Chapter 14 Session 04 - Challenge - Company Segmentation with Stock Prices", " Chapter 14 Session 04 - Challenge - Company Segmentation with Stock Prices "],
["session-04-challenge-predicting-new-product-model.html", "Chapter 15 Session 04 - Challenge - Predicting new product model", " Chapter 15 Session 04 - Challenge - Predicting new product model Here is a review of existing methods. "],
["communication-report.html", "Chapter 16 Communication - Report ", " Chapter 16 Communication - Report "],
["reports-pdf.html", "16.1 Reports (PDF)", " 16.1 Reports (PDF) Example Report with RMarkdown "],
["reports-interactive-plots.html", "16.2 Reports (Interactive Plots)", " 16.2 Reports (Interactive Plots) "],
["session-05-challenge-report.html", "Chapter 17 Session 05 - Challenge - Report", " Chapter 17 Session 05 - Challenge - Report "],
["communication-dashboard-i.html", "Chapter 18 Communication - Dashboard (I) ", " Chapter 18 Communication - Dashboard (I) "],
["flexdashboard.html", "18.1 Flexdashboard", " 18.1 Flexdashboard "],
["session-06-challenge-sales-dashboard.html", "Chapter 19 Session 06 - Challenge - Sales Dashboard", " Chapter 19 Session 06 - Challenge - Sales Dashboard "],
["communication-dashboard-ii.html", "Chapter 20 Communication - Dashboard (II) ", " Chapter 20 Communication - Dashboard (II) "],
["shiny-app.html", "20.1 Shiny App", " 20.1 Shiny App FIGURE 20.1: shiny app example in RStudio. "],
["session-07-challenge-stock-analyzer.html", "Chapter 21 Session 07 - Challenge - Stock Analyzer", " Chapter 21 Session 07 - Challenge - Stock Analyzer "],
["references.html", "References", " References "]
]
